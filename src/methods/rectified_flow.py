"""
Rectified Flow (RF)

Implements both Stage 1 (1-Rectified Flow = standard Flow Matching) and
Stage 2 (Reflow) from Liu et al. (2023):
"Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"

Stage 1 and Stage 2 use the exact same loss function (velocity matching).
The only difference is the data: Stage 1 uses real images, Stage 2 uses
synthetic (noise, image) pairs generated by the Stage 1 model.
"""

from typing import Dict, Tuple, Optional

import torch
import torch.nn as nn
import torch.nn.functional as F

from .base import BaseMethod


class RectifiedFlow(BaseMethod):
    """
    Rectified Flow method.

    For Stage 1 (standard FM): call compute_loss(x_1) with real images.
    For Stage 2 (Reflow): call compute_loss_reflow(x_0, x_1_hat) with
    synthetic pairs, or use the ReflowDataset with compute_loss.
    """

    def __init__(
        self,
        model: nn.Module,
        device: torch.device,
        num_steps: int = 50,
        t_epsilon: float = 1e-5,
    ):
        super().__init__(model, device)
        self.num_steps = int(num_steps)
        self.t_epsilon = float(t_epsilon)

    def _sample_t(self, batch_size: int, device: torch.device) -> torch.Tensor:
        """Sample t ~ U(epsilon, 1 - epsilon)."""
        t = torch.rand(batch_size, device=device)
        if self.t_epsilon > 0:
            t = t * (1.0 - 2.0 * self.t_epsilon) + self.t_epsilon
        return t

    @staticmethod
    def _reshape_t(t: torch.Tensor, x_shape: torch.Size) -> torch.Tensor:
        return t.view(t.shape[0], *([1] * (len(x_shape) - 1)))

    def compute_loss(
        self, x_1: torch.Tensor, **kwargs
    ) -> Tuple[torch.Tensor, Dict[str, float]]:
        """
        Stage 1: Standard Flow Matching loss with random (x_0, x_1) pairs.

        x_t = (1 - t) * x_0 + t * x_1
        target velocity = x_1 - x_0
        """
        batch_size = x_1.shape[0]
        x_0 = torch.randn_like(x_1)
        t = self._sample_t(batch_size, x_1.device)
        t_view = self._reshape_t(t, x_1.shape)

        x_t = (1.0 - t_view) * x_0 + t_view * x_1
        v_target = x_1 - x_0

        v_pred = self.model(x_t, t)
        loss = F.mse_loss(v_pred, v_target)
        metrics = {"loss": loss.item(), "mse": loss.item()}
        return loss, metrics

    def compute_loss_reflow(
        self, x_0: torch.Tensor, x_1_hat: torch.Tensor, **kwargs
    ) -> Tuple[torch.Tensor, Dict[str, float]]:
        """
        Stage 2: Reflow loss with synthetic (x_0, x_1_hat) pairs.

        Same loss as Stage 1, but x_1 is replaced by synthetic x_1_hat
        generated by the Stage 1 model from the same x_0.
        """
        batch_size = x_0.shape[0]
        t = self._sample_t(batch_size, x_0.device)
        t_view = self._reshape_t(t, x_0.shape)

        x_t = (1.0 - t_view) * x_0 + t_view * x_1_hat
        v_target = x_1_hat - x_0

        v_pred = self.model(x_t, t)
        loss = F.mse_loss(v_pred, v_target)
        metrics = {"loss": loss.item(), "mse": loss.item()}
        return loss, metrics

    @torch.no_grad()
    def sample(
        self,
        batch_size: int,
        image_shape: Tuple[int, int, int],
        num_steps: Optional[int] = None,
        **kwargs,
    ) -> torch.Tensor:
        """Euler ODE integration from t=0 (noise) to t=1 (data)."""
        self.eval_mode()
        device = self.device
        x = torch.randn((batch_size, *image_shape), device=device)

        steps = num_steps or self.num_steps
        t_vals = torch.linspace(0.0, 1.0, steps + 1, device=device)
        dt = t_vals[1] - t_vals[0]

        for i in range(steps):
            t = torch.full((batch_size,), t_vals[i], device=device)
            v = self.model(x, t)
            x = x + v * dt

        return x

    @torch.no_grad()
    def generate_reflow_pairs(
        self,
        batch_size: int,
        image_shape: Tuple[int, int, int],
        num_steps: int = 50,
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Generate synthetic (x_0, x_1_hat) pairs for Reflow.

        Returns:
            x_0: (B, C, H, W) noise samples
            x_1_hat: (B, C, H, W) generated images from x_0
        """
        self.eval_mode()
        device = self.device
        x_0 = torch.randn((batch_size, *image_shape), device=device)
        x = x_0.clone()

        t_vals = torch.linspace(0.0, 1.0, num_steps + 1, device=device)
        dt = t_vals[1] - t_vals[0]

        for i in range(num_steps):
            t = torch.full((batch_size,), t_vals[i], device=device)
            v = self.model(x, t)
            x = x + v * dt

        return x_0.cpu(), x.cpu()

    def to(self, device: torch.device) -> "RectifiedFlow":
        super().to(device)
        self.device = device
        return self

    def state_dict(self) -> Dict:
        state = super().state_dict()
        state["num_steps"] = self.num_steps
        state["t_epsilon"] = self.t_epsilon
        return state

    @classmethod
    def from_config(
        cls, model: nn.Module, config: dict, device: torch.device
    ) -> "RectifiedFlow":
        rf_config = config.get("rectified_flow", config.get("flow_matching", config))
        method = cls(
            model=model,
            device=device,
            num_steps=rf_config.get("num_steps", 50),
            t_epsilon=rf_config.get("t_epsilon", 1e-5),
        )
        return method.to(device)
